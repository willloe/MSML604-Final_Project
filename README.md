# ğŸ›¡ï¸ CIFAR-10 Adversarial Training with PGD

This project implements adversarial training on the CIFAR-10 dataset using **Projected Gradient Descent (PGD)** attacks, following the formulation in **Madry et al. (2018)**. The goal is to build a ResNet-18 classifier that is robust against adversarial perturbations constrained within an â„“âˆ-norm ball.

---

## ğŸ“ Project Structure

```
cifar_adversarial_project/
â”‚
â”œâ”€â”€ models/           # ResNet-18 architecture adapted for CIFAR-10
â”œâ”€â”€ attacks/          # PGD attack implementation
â”œâ”€â”€ training/         # Adversarial training loop
â”œâ”€â”€ utils/            # Evaluation helpers
â”œâ”€â”€ config.py         # Hyperparameters and global config
â”œâ”€â”€ main.py           # Entry point to launch training
â”œâ”€â”€ requirements.txt  # Required Python packages
â””â”€â”€ README.md         # Project documentation
```

---

## ğŸ§  Method: Minimax Adversarial Training

We solve the robust optimization problem:

\[
\min_\theta \; \mathbb{E}_{(x, y) \sim \mathcal{D}} \left[ \max_{\|\delta\|_\infty \leq \epsilon} \mathcal{L}(f_\theta(x + \delta), y) \right]
\]

- **Inner max**: PGD generates adversarial examples within an Îµ-ball.
- **Outer min**: model is trained to minimize loss on worst-case examples.

---

## âš™ï¸ Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

Contents of `requirements.txt`:

```
torch
torchvision
tqdm
```

---

## ğŸš€ How to Run

Run the training loop with:

```bash
python main.py
```

You can also clone and run this project on **Kaggle Notebooks** with GPU:

```python
!git clone https://github.com/YOUR_USERNAME/cifar-adversarial-project.git
%cd cifar-adversarial-project
!python main.py
```

---

## ğŸ“Š Features

- CIFAR-10 dataset (automatically downloaded)
- ResNet-18 backbone
- â„“âˆ-norm PGD adversarial attacks
- Modular structure for easy extensions

---

## ğŸ› ï¸ Future Work

- Evaluate robustness using AutoAttack
- Visualize training and adversarial examples
- Add support for â„“2-norm attacks
- Save and resume model checkpoints

---

## ğŸ“š Reference

Madry et al., [â€œTowards Deep Learning Models Resistant to Adversarial Attacksâ€](https://arxiv.org/abs/1706.06083), ICLR 2018